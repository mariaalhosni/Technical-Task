{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54e36dd4-f3e3-450e-ad8d-9e76e2ebbc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3114485c-045e-4e7d-ad90-d647dd7dfeba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:\n",
      "\n",
      "\n",
      "I am sure some bashers of Pens fans are pretty confused about the lack\n",
      "of any kind of posts about the recent Pens massacre of the Devils. Actually,\n",
      "I am  bit puzzled too and a bit relieved. However, I am going to put an end\n",
      "to non-PIttsburghers' relief with a bit of praise for the Pens. Man, they\n",
      "are killing those Devils worse than I thought. Jagr just showed you why\n",
      "he is much better than his regular season stats. He is also a lot\n",
      "fo fun to watch in the playoffs. Bowman should let JAgr have a lot of\n",
      "fun in the next couple of games since the Pens are going to beat the pulp out of Jersey anyway. I was very disappointed not to see the Islanders lose the final\n",
      "regular season game.          PENS RULE!!!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Label index: 10\n",
      "Label name: rec.sport.hockey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15076/15076 [00:54<00:00, 278.72it/s]\n",
      "100%|██████████| 3770/3770 [00:15<00:00, 238.76it/s]\n"
     ]
    }
   ],
   "source": [
    "newsgroups = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))\n",
    "data = pd.DataFrame({'text_data': newsgroups.data, 'label': newsgroups.target})\n",
    "\n",
    "entry_index = 0\n",
    "print(f\"Text:\\n{newsgroups['data'][entry_index]}\\n\\n\")\n",
    "print(f\"Label index: {newsgroups['target'][entry_index]}\")\n",
    "print(f\"Label name: {newsgroups['target_names'][newsgroups['target'][entry_index]]}\")\n",
    "\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "max_seq_len = 128\n",
    "\n",
    "def tokenize_data(data, tokenizer, max_seq_len):\n",
    "    input_ids, attention_masks, labels = [], [], []\n",
    "\n",
    "    for index, row in tqdm(data.iterrows(), total=len(data)):\n",
    "        encoded = tokenizer.encode_plus(\n",
    "            row[\"text_data\"],\n",
    "            add_special_tokens=True,  \n",
    "            max_length=max_seq_len,  \n",
    "            padding=\"max_length\",  \n",
    "            truncation=True,  \n",
    "            return_attention_mask=True, \n",
    "        )\n",
    "\n",
    "        input_ids.append(encoded[\"input_ids\"])\n",
    "        attention_masks.append(encoded[\"attention_mask\"])\n",
    "        labels.append(row[\"label\"])\n",
    "\n",
    "    # Convert lists to tensors\n",
    "    return torch.tensor(input_ids), torch.tensor(attention_masks), torch.tensor(labels)\n",
    "\n",
    "train_input_ids, train_attention_masks, train_labels = tokenize_data(train_data, tokenizer, max_seq_len)\n",
    "val_input_ids, val_attention_masks, val_labels = tokenize_data(val_data, tokenizer, max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ed95a1a-c662-4cb3-951b-fea0db083068",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "# Create a TensorDataset object for the training set\n",
    "train_dataset = TensorDataset(train_input_ids, train_attention_masks, train_labels)\n",
    "# Use RandomSampler to shuffle the samples in the dataset\n",
    "train_sampler = RandomSampler(train_dataset)\n",
    "# Create DataLoader for the training set using dataset, sampler, and batch size\n",
    "train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create a TensorDataset object for the validation set\n",
    "val_dataset = TensorDataset(val_input_ids, val_attention_masks, val_labels)\n",
    "# Use SequentialSampler to process the validation dataset sequentially\n",
    "val_sampler = SequentialSampler(val_dataset)\n",
    "# Create DataLoader for the validation set using dataset, sampler, and batch size\n",
    "val_dataloader = DataLoader(val_dataset, sampler=val_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9997e013-3fa9-4ca2-b18a-d131a5a8e23d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=20, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "\n",
    "# Load the pre-trained BERT model for sequence classification\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\",\n",
    "    num_labels=20,  \n",
    "    output_attentions=False,  \n",
    "    output_hidden_states=False, \n",
    ")\n",
    "\n",
    "# Move the model to the GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7d099ba-0c16-460d-9f82-c4e2904702bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\anaconda3\\Lib\\site-packages\\transformers\\optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Training - Loss: 0.7496: 100%|██████████| 943/943 [56:46<00:00,  3.61s/it]\n",
      "Evaluation - Batch Accuracy: 0.8000: 100%|██████████| 236/236 [05:13<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/3\n",
      "Loss: 1.4973 - Validation Accuracy: 0.6888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training - Loss: 0.1821: 100%|██████████| 943/943 [57:08<00:00,  3.64s/it]\n",
      "Evaluation - Batch Accuracy: 0.7000: 100%|██████████| 236/236 [05:18<00:00,  1.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/3\n",
      "Loss: 0.7804 - Validation Accuracy: 0.7201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training - Loss: 0.5603: 100%|██████████| 943/943 [56:33<00:00,  3.60s/it]\n",
      "Evaluation - Batch Accuracy: 0.7000: 100%|██████████| 236/236 [05:09<00:00,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3/3\n",
      "Loss: 0.5644 - Validation Accuracy: 0.7291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "num_epochs = 3\n",
    "total_steps = len(train_dataloader) * num_epochs\n",
    "\n",
    "# Create the optimizer and scheduler for fine-tuning the model\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "\n",
    "def train_epoch(model, dataloader, optimizer, scheduler, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    # Use a progress bar during training\n",
    "    progress_bar = tqdm(dataloader, desc=\"Training\", position=0, leave=True)\n",
    "\n",
    "    for batch in progress_bar:\n",
    "        input_ids, attention_masks, labels = [t.to(device) for t in batch]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_masks, labels=labels)\n",
    "        loss = outputs[0]\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        progress_bar.set_description(f\"Training - Loss: {loss.item():.4f}\")\n",
    "\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    total_eval_accuracy = 0\n",
    "\n",
    "    # Use a progress bar during evaluation\n",
    "    progress_bar = tqdm(dataloader, desc=\"Evaluation\", position=0, leave=True)\n",
    "\n",
    "    for batch in progress_bar:\n",
    "        input_ids, attention_masks, labels = [t.to(device) for t in batch]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids, attention_mask=attention_masks)\n",
    "\n",
    "        logits = outputs[0].detach().cpu().numpy()\n",
    "        label_ids = labels.cpu().numpy()\n",
    "\n",
    "        batch_accuracy = accuracy_score(label_ids, logits.argmax(axis=-1))\n",
    "        total_eval_accuracy += batch_accuracy\n",
    "\n",
    "        progress_bar.set_description(f\"Evaluation - Batch Accuracy: {batch_accuracy:.4f}\")\n",
    "\n",
    "    return total_eval_accuracy / len(dataloader)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_epoch(model, train_dataloader, optimizer, scheduler, device)\n",
    "    val_accuracy = evaluate(model, val_dataloader, device)\n",
    "\n",
    "    print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
    "    print(f\"Loss: {train_loss:.4f} - Validation Accuracy: {val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "866e6b8e-a9bc-4ad4-95ec-49df5da7efd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 236/236 [05:06<00:00,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7292\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5126    0.6182    0.5604       165\n",
      "           1     0.6869    0.7158    0.7010       190\n",
      "           2     0.7225    0.6281    0.6720       199\n",
      "           3     0.6262    0.6825    0.6532       189\n",
      "           4     0.7485    0.6893    0.7176       177\n",
      "           5     0.8315    0.8043    0.8177       184\n",
      "           6     0.8408    0.8492    0.8450       199\n",
      "           7     0.5464    0.7933    0.6471       208\n",
      "           8     0.7202    0.7092    0.7147       196\n",
      "           9     0.9382    0.8029    0.8653       208\n",
      "          10     0.9505    0.9058    0.9276       191\n",
      "          11     0.7811    0.8010    0.7909       196\n",
      "          12     0.7333    0.6842    0.7079       209\n",
      "          13     0.8558    0.8683    0.8620       205\n",
      "          14     0.7861    0.7778    0.7819       189\n",
      "          15     0.7238    0.7677    0.7451       198\n",
      "          16     0.6552    0.6425    0.6488       207\n",
      "          17     0.8424    0.8245    0.8333       188\n",
      "          18     0.5733    0.5931    0.5831       145\n",
      "          19     0.3898    0.1811    0.2473       127\n",
      "\n",
      "    accuracy                         0.7292      3770\n",
      "   macro avg     0.7233    0.7169    0.7161      3770\n",
      "weighted avg     0.7326    0.7292    0.7274      3770\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "def get_predictions(model, dataloader, device):\n",
    "    model.eval()\n",
    "    predictions, true_labels = [], []\n",
    "\n",
    "    for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "        input_ids, attention_masks, labels = [t.to(device) for t in batch]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids, attention_mask=attention_masks)\n",
    "\n",
    "        logits = outputs[0].detach().cpu().numpy()\n",
    "        label_ids = labels.cpu().numpy()\n",
    "\n",
    "        predictions.extend(logits.argmax(axis=-1))\n",
    "        true_labels.extend(label_ids)\n",
    "\n",
    "    return np.array(predictions), np.array(true_labels)\n",
    "\n",
    "predictions, true_labels = get_predictions(model, val_dataloader, device)\n",
    "\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "\n",
    "report = classification_report(true_labels, predictions, digits=4)\n",
    "\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
